.row.mt-4.mb-4
  h2 #[span.emoji ⌛️] Past Talks

.row.project
  .col-md-2.col-3
    h3.mb-0 21st
    h5.month.mb-0 January
    p 15:00-16:00
  .col-md-7.col-9
    p.author #[span.me Rudy Semola]
    h4.title.mb-1
      | CL-as-a-Service: a novel tool to Continual and Real-time machine learning
  .col-md-7
    p.abstract#talk-d7b91dcd3ee32d8e379a00c7ab7e4721.collapse.mt-2
        | Currently, for companies in different industries, it is difficult to move their ML pipelines and systems towards real-time prediction and automated, stateful training. On the other hand, some research trends that seem to overcome these limitations are Auto-ML, Continual learning, Online prediction and ML system. Recent open-source tools such as Avalanche can be exploited to build novel systems that help the companies to reduce the cost and at the same time level up their competitive technological advantage. This presentation analyzes the current European and National company industry state with step-by-step use cases, considerations, and technologies required. It is also presented the concept of Continual Learning as a Service (CLaaS) system as a general computing platform mainly based on continual learning approaches and Avalanche tool. It is shown as CLaaS is a novel computing Toolkit option for companies to support the development and deployment of machine learning models in an efficient and stateful fashion. To show the idea we have developed a lightweight CLaaS DEMO backend for researchers and engineers to exploit CL services, as well as a Rest API interface. At the end, we will discuss possible future works and research direction.
.row.project
  .col-md-2.col-3
    h3.mb-0 28th
    h5.month.mb-0 January
    p 15:00-16:00
  .col-md-7.col-9
    p.author #[span.me Tarlis Portela]
    h4.title.mb-1
      | Movelet-based Classification of Multiple Aspect Trajectories
  .col-md-7
    p.abstract#talk-a360e3e77b94b30927b97f84b5c16b92.collapse.mt-2
        | Mobility data, usually called moving object trajectories, represent the movement of objects like people, vehicles, ships. In the last decade, trajectory analysis has received significant attention. Existing trajectory classification methods have mainly considered space, time, and numerical data, ignoring the semantic dimensions. A recent line of approaches is called Movelet-based methods and it has been shown that they outperform the state-of-the-art in terms of classification accuracy. However, it is computationally unfeasible for most real trajectory datasets that contain big volumes of high dimensional data. We will show some methods called MASTERMovlelets, SUPERMovelets, and HiPerMovelets that provide a good trade off between classification accuracy and running time and we will discuss possible future works.
.row.project
  .col-md-2.col-3
    h3.mb-0 4th
    h5.month.mb-0 February
    p 15:00-16:00
  .col-md-7.col-9
    p.author #[span.me Riccardo Massidda]
    h4.title.mb-1
      | Concept-Based Methods for Neural Network Interpretation
  .col-md-7
    p.abstract#talk-89ee1ad65c602ab48f5110f2fe9e267e.collapse.mt-2
        | Concept-based methods attempt to interpret existing neural networks or to design inherently interpretable models by exploiting human-comprehensible concepts. In the current talk, I will present few significant examples of such methods, discussing their commonalities, their underlying assumptions, and their applications. More in detail, I will focus on the semantic alignment of neural directions and visual concepts in CNNs for computer vision. In this context, different existing approaches might be understood in terms of a unified general framework. Furthermore, I will show the impact of acknowledging semantic relations on such framework. Finally, the talk discusses the main issues affecting concept-based methods and hints to possible research strategies to tackle them.
.row.project
  .col-md-2.col-3
    h3.mb-0 11th
    h5.month.mb-0 February
    p 15:00-16:00
  .col-md-7.col-9
    p.author #[span.me Arslan Siddique]
    h4.title.mb-1
      | Automatic key frame selection for video-based structure from motion pipelines
  .col-md-7
    p.abstract#talk-7f3f92dc59f649364f5526815075bd1b.collapse.mt-2
        | Structure from motion (SfM) is a photogrammetric imaging technique that refers to estimating 3D object models using a range of 2D images. 3D object models can be constructed from a 2D video sequence taken using a hand-held camera. However, processing all frames leads to a very high computational complexity and poor results. Automatic key frame selection significantly reduces computational time and improves the accuracy of Structure from Motion pipelines. In the first stage, features are extracted and tracked throughout the sequence. In a second stage stereo matching is used to obtain a detailed estimate of the geometry of the observed scene and compute frame-to-frame Homography and Fundamental matrices. Finally, a geometric robust information criterion (GRIC) is computed to decide the removal of this frame. The method has been tested on a test scenario containing some stationary scenes and experiments show that the proposed method is able to discard the frames corresponding to stationary scenes. 
.row.project
  .col-md-2.col-3
    h3.mb-0 18th
    h5.month.mb-0 February
    p 15:00-16:00
  .col-md-7.col-9
    p.author #[span.me Andrea Guerra]
    h4.title.mb-1
      | PIR: Private Information Retrieval
  .col-md-7
    p.abstract#talk-e001100025bd1526e0397c7d5f669a02.collapse.mt-2
        | How can a user retrieve an item from a server in possession of a database without revealing which item was retrieved? The Private Information Retrieval (PIR) in cryptography is a protocol used to answer this question. So, PIR allows a client to download an element (e.g., movie, friend record) from a database held by an untrusted server without revealing to the server which element was downloaded. In this talk, we will see the importance of this problem and the challenges it presents. Indeed, PIR is a key building block in many privacy-preserving systems, unfortunately, existing constructions remain very expensive. This expense is fundamental: PIR schemes force the server to operate on all elements in the database to answer a single query, furthermore, to protect the privacy of the query, PIR schemes require the user to send n ciphertexts where n is the size of the database.
.row.project
  .col-md-2.col-3
    h3.mb-0 25th
    h5.month.mb-0 February
    p 15:00-16:00
  .col-md-7.col-9
    p.author #[span.me Jacopo Massa]
    h4.title.mb-1
      | Data-aware application placement and routing in the Cloud-IoT continuum
  .col-md-7
    p.abstract#talk-65c5a835116e193addcf400ddb633b01.collapse.mt-2
        | With the widespread adoption of the Internet Of Things (IoT), billions of devices are now connected to the Internet and can reach computing facilities along the Cloud-IoT continuum to process the data they produce. This led to a dramatic increase in the deployed IoT-based applications as well as in the data they need to crunch. Those applications oftentimes have Quality of Service (QoS) requirements to be met by determining suitable placements for all processing and data services they are made of, and software-defined routings across the IoT and all different application components. Following a continuous reasoning approach, I will show you a modelling of Cloud-IoT infrastructures and multi-service applications, a methodology that permits determining eligible service placements and data traffic routings over Cloud-IoT resources, along with a Prolog prototype which implements both the presented model and methodology.
.row.project
  .col-md-2.col-3
    h3.mb-0 4th
    h5.month.mb-0 March
    p 15:00-16:00
  .col-md-7.col-9
    p.author #[span.me Cosimo Rulli]
    h4.title.mb-1
      | Deep Neural Network Compression
  .col-md-7
    p.abstract#talk-ef5b2cf28c5ecbca43955a309f99ee8a.collapse.mt-2
        | Deep Neural Networks (DNNs) deliver state-of-the-art performance in a plethora of different tasks, such Computer Vision, Natural Language Processing and Speech Recognition. Their effectiveness comes at the price of an elevated computational burden, in terms of memory occupancy, inference time, and energy consumption, which hinders their usage in resource-constrained devices. Model Compression techniques tackle this problem by leveraging the largely proved over-parametrization of modern DNNs and aim at the reducing the computational requirements of DNNs without affecting their accuracy. In this seminar, we illustrate the taxonomy of DNNs compression methods, particularly focusing on quantization, pruning and knowledge distillation. We introduce their technical aspects, and discuss the different trade-offs between computational burden and accuracy that each technique allows to achieve.
.row.project
  .col-md-2.col-3
    h3.mb-0 11th
    h5.month.mb-0 March
    p 15:00-16:00
  .col-md-7.col-9
    p.author #[span.me Martina Cinquini]
    h4.title.mb-1
      | CALIME: Causality-Aware Local Interpretable Model-agnostic Explanations
  .col-md-7
    p.abstract#talk-f25df3728ef8e03c4ea746ad3be8a3a0.collapse.mt-2
        | Over the last few years, eXplainable Artificial Intelligence (XAI) methods have been experiencing a wave of popularity due to their ability to provide human-understandable explanations that express the rationale of black-box models used by decision-making systems. Despite the widespread adoption of these procedures, a significant drawback of XAI methods is the assumption of features independence that implies the inability to rely on direct knowledge about potential dependencies among variables. Indeed, black-box behaviors are typically approximated by studying the effects on randomly generated feature values that might rarely appear in original samples. As a consequence, post-hoc explanation methods can capture associations in the data between input features and target class without guaranteeing the presence of any causal relationships among input features. We introduce an extended version of a widely used local and model-agnostic explainer that explicitly encodes causal relationships in the data generated around the input instance for which the explanation is required.
.row.project
  .col-md-2.col-3
    h3.mb-0 18th
    h5.month.mb-0 March
    p 15:00-16:00
  .col-md-7.col-9
    p.author #[span.me Flavio Ascari]
    h4.title.mb-1
      | Extensive, locally complete abstract interpretation
  .col-md-7
    p.abstract#talk-0326aae7b72de998d20a9a29dd7f6753.collapse.mt-2
        | Abstract interpretation is a framework to design sound static analyses which over-approximate the set of program behaviours. While this can prove correctness, it can't show incorrectness because false alarms may arise from the over-approximation. These may undermine the credibility of a static analysis tool, making it less effective in practice. For abstract interpretation, an ideal but very uncommon situation is completeness, in which the abstract interpreter doesn't introduce false alarms, hence coming out more reliable. However, to our knowledge methods to show completeness-like properties deal with intensional (ie. dependant on syntax) abstractions of a program, while completeness itself is an extensional property of the program semantics only. In the talk, we propose an extension of Local Completeness Logic, an Hoare-style logic to prove completeness of the abstraction of a program c on an input P. Our main contribution is the addition of a new rule we call (refine-ext). This rule allows to perform part of the analysis in a finer abstract domain, then to move the result to the coarser one without any precision loss. With this addition, the logic is able to prove all triples where the extensional best correct approximation of the program semantics is locally complete, thus untying the set of provable properties from the way the program is written.
.row.project
  .col-md-2.col-3
    h3.mb-0 25th
    h5.month.mb-0 March
    p 15:00-16:00
  .col-md-7.col-9
    p.author #[span.me Federica Di Pasquale]
    h4.title.mb-1
      | Mixed Integer Programming Solvers
  .col-md-7
    p.abstract#talk-a7ff5d571b7acbc02556fc7b7a155162.collapse.mt-2
        | Mixed Integer Programming (MIP) Solvers are powerful tools for solving hard optimization problems. Over the past 60 years, both commercial and open-source MIP solvers have made tremendous progress thanks to the increasingly sophisticated techniques that have been developed. The core solution algorithm is common to most of the current state-of-the-art MIP solvers and it is called Branch and Cut, as it is an intermediate approach in between the generic Branch and Bound scheme and the Cutting Plane algorithm. However, the implementation details usually have a huge impact on the overall performances of a MIP solver. In this presentation, we will see the basic ideas of a Branch and Cut algorithm and a description of the main components of a MIP solver. Finally, we will discuss some possible research directions in order to achieve further improvements. 